{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "import spotipy.util as util\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a username and a playlist_dict, generate a dataframe of 'similar' songs\n",
    "#PFI: This function could be way more robust, looking at a artists/genres as well as randomizing/subsampling to improve speed\n",
    "\n",
    "# TODO: Get Recommendations off of Recommendations (probably only want to do recursively once)\n",
    "def get_similar_tracks_from_playlist(username_var, playlist_var, spotipy_connection):\n",
    "    top_level_tracks = spotipy_connection.user_playlist(username_var, playlist_var['id'],\n",
    "                    fields=\"tracks,next\")\n",
    "    second_level_tracks = top_level_tracks['tracks']\n",
    "    playlist_var_track_ids = [None]*len(second_level_tracks['items'])\n",
    "    playlist_var_artist_ids = [None]*len(second_level_tracks['items'])\n",
    "    # playlist_1_genre_ids = [None]*len(second_level_tracks['items'])\n",
    "    for i, item in enumerate(second_level_tracks['items']):\n",
    "        cur_track = item['track']\n",
    "        playlist_var_track_ids[i] = cur_track['id']\n",
    "#        playlist_var_artist_ids[i] = cur_track['artists'][0]['id']\n",
    "\n",
    "\n",
    "## Sometimes we get a track with a \"none\" value, get rid of these (this could reset indexing, don't rely on indices)\n",
    "    playlist_var_track_ids = [x for x in playlist_var_track_ids if x != None]\n",
    "\n",
    "    rec_tracks_list = [None]*int((len(playlist_var_track_ids)/5)-1)\n",
    "    for i in range(0,len(rec_tracks_list)):\n",
    "        rec_tracks_list[i] = spotipy_connection.recommendations(seed_tracks = playlist_var_track_ids[i*5:(i+1)*5])\n",
    "        \n",
    "    # rec_tracks_list is a list of lists, each sublist has a track\n",
    "    # extract out to a single list\n",
    "    rec_tracks_list_full = [None]*20*len(rec_tracks_list)\n",
    "\n",
    "    # Iterate over all sets of recommendations from groups of 5 songs\n",
    "    for i, rec_set in enumerate(rec_tracks_list):\n",
    "\n",
    "        # Iterate over every track\n",
    "        for j, tracks in enumerate(rec_set['tracks']):\n",
    "            rec_tracks_list_full[i*20 + j] = tracks['id']\n",
    "            #print(tracks['artists'][0]['name'], ': ', tracks['name'], sep = '')\n",
    "\n",
    "    all_track_ids = pd.DataFrame(np.array(rec_tracks_list_full))\n",
    "    all_track_ids.columns=['track_id']\n",
    "    return all_track_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_features(track_df, spotipy_connection):\n",
    "\n",
    "    track_df_var = copy.deepcopy(track_df)\n",
    "    new_cols = list(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo'])\n",
    "\n",
    "    # Create all new columns for feature types\n",
    "    for col in new_cols:\n",
    "        # Initialize Column as empty\n",
    "        track_df_var[col] = np.nan\n",
    "        # Run over each row\n",
    "    for i in range(0, len(track_df_var)):\n",
    "        # Get features for current song\n",
    "        cur_track_features = spotipy_connection.audio_features(track_df_var['track_id'][[i]])\n",
    "        #Insert specific feature into column\n",
    "        #TODO: This currently calls the sp.audio_features like 10 times for each song (since I do it for each row)\n",
    "        for col in new_cols:\n",
    "            track_df_var[col].iloc[i] = cur_track_features[0][col]\n",
    "    \n",
    "    return track_df_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a playlist (and the username of its owner) return a dataframe of the track IDs\n",
    "\n",
    "def get_tracks_from_playlist(username, playlist, spotipy_connection):\n",
    "    \n",
    "    # Do some stuff to account for the hierarchical structure of what we get back\n",
    "    top_level_tracks = spotipy_connection.user_playlist(username, playlist['id'],\n",
    "                    fields=\"tracks,next\")\n",
    "\n",
    "    second_level_tracks = top_level_tracks['tracks']\n",
    "    \n",
    "    # Initialize empty list for track_ids\n",
    "    playlist_track_ids = [None]*len(second_level_tracks['items'])\n",
    "    \n",
    "    #PFI: could do something similar for artist/genre and Pear on those as well\n",
    "    #playlist_var_artist_ids = [None]*len(second_level_tracks['items'])\n",
    "    # playlist_1_genre_ids = [None]*len(second_level_tracks['items'])\n",
    "    \n",
    "    for i, item in enumerate(second_level_tracks['items']):\n",
    "        cur_track = item['track']\n",
    "        playlist_track_ids[i] = cur_track['id']\n",
    "        #playlist_var_artist_ids[i] = cur_track['artists'][0]['id']\n",
    "\n",
    "\n",
    "    # Sometimes we get a track with a \"none\" value, get rid of these \n",
    "    playlist_track_ids = [x for x in playlist_track_ids if x != None]\n",
    "    # Make it a DF\n",
    "    to_return = pd.DataFrame(np.array(playlist_track_ids))\n",
    "    to_return.columns=['track_id']\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a set of chosen playlist names, and the returned API call of all the user's playlists (dict of each playlist)\n",
    "# returns a list of individual playlist (dict) objects matching the names provided\n",
    "def get_api_playlists_from_names(chosen_playlist_names, all_api_playlists):\n",
    "    # Initialize List to place playlists in\n",
    "    chosen_api_playlists = [None]*len(chosen_playlist_names)\n",
    "    \n",
    "    # Iterate over each name, then all items in api, then check for match (PSI: double for loops are bad?)\n",
    "    for i, playlist_name in enumerate(chosen_playlist_names):\n",
    "        for api_playlist in all_api_playlists['items']:\n",
    "            if(api_playlist['name'] == playlist_name):\n",
    "                chosen_api_playlists[i] = api_playlist\n",
    "    \n",
    "    return chosen_api_playlists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# Given List of N dfs with tracks as rows and audio features as columns\n",
    "# Union all, do PCA (so that they're all on the same scale) then separate out into list of DFs\n",
    "\n",
    "def pca_merge(feature_dfs):\n",
    "    all_features_tmp = pd.DataFrame(columns = feature_dfs[0].columns)\n",
    "    all_features_tmp['playlist_iter'] = None\n",
    "    feature_dfs_copy = copy.deepcopy(feature_dfs)\n",
    "    for i, playlist_features in enumerate(feature_dfs_copy):\n",
    "        playlist_features['playlist_iter'] = i\n",
    "        all_features_tmp = all_features_tmp.append(playlist_features)\n",
    "\n",
    "\n",
    "\n",
    "    # Mode and Key make PCA look weird (at least for graphing) - take them out for time being\n",
    "    # PFI: Take a look at this again, maybe they're useful, but just not in visualization\n",
    "    all_features = all_features_tmp.drop(['mode', 'key'], axis = 1).reset_index()\n",
    "\n",
    "    # Actual PCA\n",
    "    x = all_features.drop(['playlist_iter', 'track_id'], axis = 1)\n",
    "    # Standardizing the features\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "\n",
    "    #TODO: Adjust to dynamically create table so that we can have n principal components\n",
    "    pca = PCA(n_components=3)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "    playlists_finalDf = pd.concat([principalDf,  all_features[['playlist_iter']]], axis = 1)\n",
    "\n",
    "    return playlists_finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given set of Playlist_bases objects, get a distance matrix of all tracks to all other tracks (will be redundancies)\n",
    "# Assumes the rec_tracks_df of all base playlists is the same\n",
    "def get_track_distances_tmp(playlist_bases):\n",
    "\n",
    "    # Need a df with all tracks as rows\n",
    "    # All features as columns\n",
    "    \n",
    "    # Create empty data frame to union results onto\n",
    "    all_rec_tracks_tmp = pd.DataFrame(columns = playlist_bases[0].rec_tracks_df.columns)\n",
    "    all_orig_tracks_tmp = pd.DataFrame(columns = playlist_bases[0].orig_playlist_tracks_df.columns)\n",
    "    \n",
    "    for playlist_base in playlist_bases:\n",
    "        rec_tracks_df = playlist_base.rec_tracks_df\n",
    "        all_rec_tracks_tmp = all_rec_tracks_tmp.append(rec_tracks_df)\n",
    "        orig_playlist_tracks_df = playlist_base.orig_playlist_tracks_df\n",
    "        all_orig_tracks_tmp = all_orig_tracks_tmp.append(orig_playlist_tracks_df)\n",
    "        \n",
    "    # Mode & Key did bad stuff in early analysis\n",
    "    all_rec_tracks = all_rec_tracks_tmp.reset_index().drop(['index','mode', 'key'], axis = 1)\n",
    "    all_orig_tracks = all_orig_tracks_tmp.reset_index().drop(['index','mode', 'key'], axis = 1)\n",
    "    \n",
    "    # Now get all original tracks, compare distance \n",
    "\n",
    "\n",
    "    all_tracks = all_rec_tracks.append(all_orig_tracks).reset_index().drop(['index'], axis = 1)\n",
    "    \n",
    "    all_tracks_scaled = pd.DataFrame(StandardScaler().fit_transform(all_tracks.drop(['track_id'], axis = 1)))\n",
    "\n",
    "    \n",
    "    all_rec_tracks_scaled = all_tracks_scaled.iloc[0:len(all_rec_tracks)]\n",
    "    all_rec_tracks_scaled['track_id'] = all_rec_tracks['track_id']\n",
    "    all_orig_tracks_scaled = all_tracks_scaled.iloc[len(all_rec_tracks):all_tracks_scaled.shape[0]].reset_index().drop(['index'], axis = 1)\n",
    "    all_orig_tracks_scaled['track_id'] = all_orig_tracks['track_id']\n",
    "    \n",
    "    all_tracks_scaled['track_id'] = all_tracks['track_id']\n",
    "    ### Normalize that shit before doing the distance matrix, have to put in same df to normalize\n",
    "    ### \n",
    "#    dist_matrix = pd.DataFrame(distance_matrix(all_rec_tracks.drop(['track_id'], axis = 1).values, all_orig_tracks.drop(['track_id'], axis = 1).values))\n",
    "    dist_matrix = pd.DataFrame(distance_matrix(all_rec_tracks_scaled.drop(['track_id'], axis = 1).values, all_orig_tracks_scaled.drop(['track_id'], axis = 1).values))\n",
    "    \n",
    "    # Now have a distance matrix whose rows are all of our recommended tracks\n",
    "    # Columns are all original tracks, and values are the distance between the songs (after all were normalized together)\n",
    "    # Make the column names and row names the actual track_ids \n",
    "    dist_matrix.columns = all_orig_tracks['track_id']\n",
    "    dist_matrix.insert(0, 'track_id', all_rec_tracks['track_id'])\n",
    "    \n",
    "    \n",
    "    return dist_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist(access_token, user_id, title):\n",
    "    cp_headers = {'Authorization': access_token, 'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "    cp_post = {'name': title, 'public': 'true', 'collaborative': 'false',\n",
    "               'description': 'testing this out'}\n",
    "    cp_url = 'https://api.spotify.com/v1/users/' + user_id.decode(\"utf-8\") + '/playlists'\n",
    "    r_cp = requests.post(cp_url, headers=cp_headers, data=json.dumps(cp_post))\n",
    "\n",
    "    print (r_cp.status_code)\n",
    "\n",
    "    if str(r_cp.status_code) != '201':\n",
    "        print (r_cp.json())\n",
    "\n",
    "        return \"It didnt work yo - try again\"\n",
    "    r_cp_json = r_cp.json()\n",
    "    playlist_id = r_cp_json['id']\n",
    "    owner_id = r_cp_json['owner']['id']\n",
    "    #full_pl = base64.b64encode(owner_id + '/' + playlist_id)\n",
    "    # for delay testing purposes\n",
    "    return  playlist_id #full_pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pear_Playlists(playlist_name_1, playlist_name_2, access_token, user_id):\n",
    "    ### INITIALIZE THINGS\n",
    "    p1_base = Playlist_Base(playlist_name = p1_name, user_id = user_id, access_token = access_token)\n",
    "    p2_base = Playlist_Base(playlist_name = p2_name, user_id = user_id, access_token = access_token)\n",
    "    \n",
    "    playlist_bases = [p1_base, p2_base]\n",
    "    \n",
    "    track_distances = get_track_distances_tmp(playlist_bases)\n",
    "    \n",
    "    \n",
    "    ### FIND TRACKS\n",
    "    # Look at each recommended track\n",
    "    # Store each track in a df, with each column being the distance to one of the playlists\n",
    "    p0_track_ids = playlist_bases[0].orig_playlist_tracks_df['track_id']\n",
    "    p1_track_ids = playlist_bases[1].orig_playlist_tracks_df['track_id']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Make 3 lists to insert into data frame - PFI: need a more robust solution for more playlists\n",
    "    track_ids = [None]*len(track_distances)\n",
    "    p0_dist = [None]*len(track_distances)\n",
    "    p1_dist = [None]*len(track_distances)\n",
    "    for index, rec_track in track_distances.iterrows():\n",
    "        # The index of each 'rec_track' is every column in the df (aka all original tracks)\n",
    "        # We want to subset this to the specific playlists so that we can determine distance to each playlist\n",
    "        track_ids[index] = rec_track['track_id']\n",
    "\n",
    "        # the track ids in p0_track_ids should match the columns (aka index) of rec_track\n",
    "        # Only look at those, then get avg dist\n",
    "        p0_track_distances = rec_track[rec_track.index.isin(p0_track_ids)]\n",
    "        p0_dist[index] = p0_track_distances.mean()\n",
    "\n",
    "        p1_track_distances = rec_track[rec_track.index.isin(p1_track_ids)]\n",
    "        p1_dist[index] = p1_track_distances.mean()\n",
    "\n",
    "    cols = ['track_id', 'p0', 'p1']\n",
    "    rec_tracks_to_playlists = pd.DataFrame({'track_id' : track_ids, 'p0': p0_dist, 'p1' : p1_dist})\n",
    "    rec_tracks_to_playlists['avg_dist'] = rec_tracks_to_playlists.mean(axis = 1)\n",
    "    final_tracks = rec_tracks_to_playlists.sort_values(by = ['avg_dist']).iloc[0:20]\n",
    "    \n",
    "    ### BUILD PLAYLIST\n",
    "    sp = spotipy.Spotify(auth=access_token[7:])\n",
    "    playlist_id = create_playlist(access_token, user_id.encode(), \"SpotiPear_Test_Playlist\")\n",
    "    # Now let's add some tracks\n",
    "    track_ids_to_add = final_tracks['track_id']\n",
    "    # TODO: Dynamically pull playlistid\n",
    "    sp.user_playlist_add_tracks(user_id, playlist_id, track_ids_to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
